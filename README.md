William Stetar
**AI Safety Researcher | Computational Linguist | Systems Developer**

I analyze language model behavior through computational linguistics, focusing on how discourse patterns shape alignment failures. I also build tools for LLM integration, git automation, and symbolic reasoning systems.
Current Research: Investigating epistemic failure modes in LLMs using Systemic Functional Linguistics‚Äîspecifically how models prioritize interpersonal coherence over factual accuracy under pressure.
Technical Skills: Go, Python, Bash, C#, SQL | LLM integration | CLI tooling | Git automation

**Projects**

- PRbuddy - Auto-generates pull request drafts using Git hooks and LLM infrastructure
github.com/soyuz43/PRbuddy

- Symbolic Grammar Interpreter - Recursive system for analyzing contradiction and structural drift in text
github.com/soyuz43/Symbolic-Grammar-Interpreter

- Holoplan CLI - Transforms user stories into Draw.io wireframes via multi-agent LLM reasoning
github.com/soyuz43/holoplan-cli

**Writing & Research**

üìù [Hashnode Blog](https://copin43.hashnode.dev/) - Essays on AI safety, linguistic analysis, and ethical implications of LLMs
Notable pieces:

"The Nuremberg Defense of AI" - On accountability in ML development
"Epistemic Autoimmunity" - Framework for analyzing alignment failures through discourse patterns


Contact
üìß kebekad673@proton.me
üîó [LinkedIn](https://www.linkedin.com/in/copin43)
